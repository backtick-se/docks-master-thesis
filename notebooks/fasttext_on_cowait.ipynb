{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7087df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load, dump, load_ft_data\n",
    "from evaluate import eval\n",
    "from os import getcwd\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from build import categories\n",
    "import fasttext\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cf5125b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = f'{getcwd()}/..'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f933867e",
   "metadata": {},
   "source": [
    "## Let's try applying the fasttext classifier on our annotated Cowait data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "851d7497",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(f'{root}/data/prd_backtick-se_cowait_annotated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "509176a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model(f\"{root}/models/fasttext_base.bin\")\n",
    "\n",
    "def predict(text):\n",
    "    return model.predict(text)[0][0][9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "18e32d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for pr in data:\n",
    "    title = pr['title']\n",
    "    pcat = predict(title)\n",
    "    tcat = pr['category']\n",
    "    \n",
    "    y_true.append(tcat)\n",
    "    y_pred.append(pcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "efc568ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      fix-bugs       0.18      0.69      0.29        32\n",
      "  new-features       0.35      0.18      0.24        49\n",
      " documentation       0.29      0.25      0.27         8\n",
      "non-functional       0.56      0.16      0.25        91\n",
      "\n",
      "      accuracy                           0.27       180\n",
      "     macro avg       0.34      0.32      0.26       180\n",
      "  weighted avg       0.42      0.27      0.26       180\n",
      "\n",
      "[[22  7  1  2]\n",
      " [33  9  0  7]\n",
      " [ 1  2  2  3]\n",
      " [64  8  4 15]]\n"
     ]
    }
   ],
   "source": [
    "eval(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9510d5",
   "metadata": {},
   "source": [
    "## Why is the model eager to set the fix-bug category?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94b280",
   "metadata": {},
   "source": [
    "Hypothesis is that it was trained on unevenly distributed class data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "668321c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data, label_data = load_ft_data(f'{root}/data/fasttext_data.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "721e317e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fix: \t185640 \t(0.48)\n",
      "new: \t73009 \t(0.19)\n",
      "doc: \t42090 \t(0.11)\n",
      "non: \t84780 \t(0.22)\n"
     ]
    }
   ],
   "source": [
    "tot = len(label_data)\n",
    "\n",
    "for cat in categories:\n",
    "    m = label_data.count(cat)\n",
    "    print(f'{cat:.3}: \\t{m} \\t({m/tot:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b1a944",
   "metadata": {},
   "source": [
    "Hypothesis holds - it was indeed trained on very unevenly distributed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c480ae3",
   "metadata": {},
   "source": [
    "## Inspecting the evaluation of validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9b81bfad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      fix-bugs       0.95      0.98      0.96      2411\n",
      "  new-features       0.93      0.96      0.95       970\n",
      " documentation       0.94      0.92      0.93       549\n",
      "non-functional       0.96      0.88      0.92      1070\n",
      "\n",
      "      accuracy                           0.95      5000\n",
      "     macro avg       0.94      0.93      0.94      5000\n",
      "  weighted avg       0.95      0.95      0.95      5000\n",
      "\n",
      "[[2353   25   11   22]\n",
      " [  27  934    1    8]\n",
      " [  27    7  504   11]\n",
      " [  71   39   19  941]]\n"
     ]
    }
   ],
   "source": [
    "val_titles, val_labels = load_ft_data(f'{root}/data/fasttext_data.valid')\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for title, label in zip(val_titles, val_labels):\n",
    "    pred = predict(title)    \n",
    "    y_pred.append(pred)\n",
    "    y_true.append(label)\n",
    "\n",
    "eval(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e9f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
