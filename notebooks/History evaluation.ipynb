{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from os import chdir\n",
    "import subprocess\n",
    "from dateutil.parser import parse\n",
    "import os\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"...\"\n",
    "headers = {'Authorization': 'token ' + token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"pallets/flask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_responses(token, url):\n",
    "    responses = []\n",
    "    while True:\n",
    "        headers = {'Authorization': 'token ' + token}\n",
    "        rsp = requests.get(url, headers=headers)\n",
    "        responses.append(rsp)\n",
    "        if 'next' in rsp.links:\n",
    "            url = rsp.links['next']['url']\n",
    "        else:\n",
    "            break\n",
    "    return responses\n",
    "\n",
    "def rate_limit(response):\n",
    "    print(\"Rate remaining:\", response.headers['X-RateLimit-Remaining'])\n",
    "    print(\"Rate limit reset:\", datetime.fromtimestamp(int(response.headers['X-RateLimit-Reset'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch PRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.github.com/search/issues?q=repo:pallets/flask+is:merged+base:main&per_page=100'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f\"https://api.github.com/search/issues?q=repo:{repo}+is:merged+base:main&per_page=100\"\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Response [200]>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = fetch_responses(token, url)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate remaining: 29\n",
      "Rate limit reset: 2022-03-25 16:14:51\n"
     ]
    }
   ],
   "source": [
    "rate_limit(responses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = []\n",
    "for response in responses:\n",
    "    items += response.json()['items']\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4492, 4491, 4488, 4487, 4486]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [x['number'] for x in items]\n",
    "numbers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:23<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pulls_resps = []\n",
    "for number in tqdm(numbers):\n",
    "    url = f\"https://api.github.com/repos/{repo}/pulls/{number}\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    pulls_resps.append(resp)\n",
    "print(set([x.status_code for x in pulls_resps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate remaining: 4917\n",
      "Rate limit reset: 2022-03-25 17:04:53\n"
     ]
    }
   ],
   "source": [
    "rate_limit(pulls_resps[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d01d26e5210e3ee4cbbdef12f05c886e08e92852\n",
      "048709c8e7d4d3916193bd2c735ee93c073ab686\n",
      "d7199c87854c574f46288fd1086fa31fb42c1446\n",
      "e4373eba1cdd4b288b9d37e784bd26e0ca32056c\n",
      "0826be48ed50c9ac73160ba7225715659961a992\n",
      "f5f51cd09c094cc15e7e6385cf27564bedc30b1b\n",
      "4550beb695e9090259957d4ea1a7a8af9d7b2802\n",
      "625595cb1a0a70c34a82b5c151d02e6359d5e191\n",
      "e248e09399b21b0d21d3c8005a30c4dc4d430faa\n",
      "48ee204dd5bdc47f397553fb45b5fe37003c07d1\n"
     ]
    }
   ],
   "source": [
    "for pr in pulls_resps[20:30]:\n",
    "    print(pr.json()['merge_commit_sha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['url', 'id', 'node_id', 'html_url', 'diff_url', 'patch_url', 'issue_url', 'number', 'state', 'locked', 'title', 'user', 'body', 'created_at', 'updated_at', 'closed_at', 'merged_at', 'merge_commit_sha', 'assignee', 'assignees', 'requested_reviewers', 'requested_teams', 'labels', 'milestone', 'draft', 'commits_url', 'review_comments_url', 'review_comment_url', 'comments_url', 'statuses_url', 'head', 'base', '_links', 'author_association', 'auto_merge', 'active_lock_reason', 'merged', 'mergeable', 'rebaseable', 'mergeable_state', 'merged_by', 'comments', 'review_comments', 'maintainer_can_modify', 'commits', 'additions', 'deletions', 'changed_files'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pulls_resps[0].json().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6751979, 6751980}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milestones = set()\n",
    "for pr in pulls_resps:\n",
    "    pr = pr.json()\n",
    "    if pr['milestone']:\n",
    "        milestones.add(pr['milestone']['id'])\n",
    "milestones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prs = {}\n",
    "for pr in pulls_resps:\n",
    "    pr = pr.json()\n",
    "    sha = pr['merge_commit_sha']\n",
    "    prs[sha] = {\n",
    "        'title': pr['title'],\n",
    "        'sha': sha\n",
    "    }\n",
    "len(prs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{200}\n"
     ]
    }
   ],
   "source": [
    "url = f\"https://api.github.com/repos/{repo}/releases?per_page=100\"\n",
    "release_resps = fetch_responses(token, url)\n",
    "print(set([x.status_code for x in release_resps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.0.3'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_tags = set()\n",
    "for r in release_resps[0].json():\n",
    "    if r['target_commitish'] == 'main' and r['draft'] == False and r['prerelease'] == False:\n",
    "        release_tags.add(r['tag_name'])\n",
    "print(len(release_tags))\n",
    "list(release_tags)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate remaining: 4916\n",
      "Rate limit reset: 2022-03-25 17:04:53\n"
     ]
    }
   ],
   "source": [
    "rate_limit(release_resps[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['url', 'assets_url', 'upload_url', 'html_url', 'id', 'author', 'node_id', 'tag_name', 'target_commitish', 'name', 'draft', 'prerelease', 'created_at', 'published_at', 'assets', 'tarball_url', 'zipball_url', 'body', 'reactions'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_resps[0].json()[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/pallets/flask/releases/tag/2.0.3'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_resps[0].json()[0]['html_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kontrollera att alla PR, tags finns med lokalt\n",
    "\n",
    "- Plocka ut en lista med alla sha lokalt\n",
    "- Map pr->sha för att kolla om alla pr finns i historiken\n",
    "- Kan även kolla för release tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='git clone https://github.com/pallets/flask', returncode=128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(f\"git clone https://github.com/{repo}\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flask'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_dir = repo.split('/')[-1]\n",
    "repo_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4577\n",
      "['33850c0ebd23ae615e6823993d441f46d80b1ff0', 'b15ad394279fc3b7f998fa56857f334a7c0156f6', '4ec7d2a0d8eac4f915dc0d38a886cd57045bb0c4']\n",
      "\n",
      "{'ef557b3ff2602b9956a2f3ac02c6e134c529fccc': '2.0.3', '6f7762538bffe3ce9d03508ecab230bfff3e3dcd': '2.0.2', 'bc90801c2ada42d3cf112a3b5701bfdbb8b6211c': '2.0.1', '2f0c62f5e6e290843f03c1fa70817c7a3c7fd661': '2.0.0'}\n"
     ]
    }
   ],
   "source": [
    "chdir(repo_dir)\n",
    "try:\n",
    "    subprocess.run(\"git checkout main\", shell=True)\n",
    "    \n",
    "    lines = subprocess.getoutput(\"git log --format=format:%H\").split('\\n')\n",
    "    commits = list(reversed(lines))\n",
    "    print(len(commits))\n",
    "    print(commits[:3])\n",
    "    \n",
    "    print()\n",
    "    all_tags = {}\n",
    "    for tag in release_tags:\n",
    "        # OBS: Detta inkluderar även tags från andra branches...\n",
    "        lines = subprocess.getoutput(f\"git rev-list -n 1 {tag}\").split('\\n')\n",
    "        sha = lines[0]\n",
    "        all_tags[sha] = tag\n",
    "    print(all_tags)\n",
    "finally:\n",
    "    chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4577"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in prs.keys():\n",
    "    assert key in commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 release tags on main\n"
     ]
    }
   ],
   "source": [
    "# Endast tag från main\n",
    "tags = {}\n",
    "for sha, tag in all_tags.items():\n",
    "    if sha in commits:\n",
    "        tags[sha] = tag\n",
    "\n",
    "print(len(tags), \"release tags on main\")\n",
    "for key in tags.keys():\n",
    "    assert key in commits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sektionera PR mellan releases\n",
    "\n",
    "Gå igenom alla commits i 2 vändor O(2*n) = O(n)\n",
    "1. Extrahera tags -> sections {start: tag, prs: [], end: tag}\n",
    "2. Öka section för varje tag och lägg till pr på rätt plats\n",
    "\n",
    "Ordningen baseras på commits i main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': '2.0.0', 'prs': [], 'end': '2.0.1'}\n",
      "{'start': '2.0.1', 'prs': [], 'end': '2.0.2'}\n",
      "{'start': '2.0.2', 'prs': [], 'end': '2.0.3'}\n"
     ]
    }
   ],
   "source": [
    "tag_commits = [c for c in commits if c in tags]\n",
    "\n",
    "sections = []\n",
    "for i in range(len(tag_commits)-1):\n",
    "    sections.append({\n",
    "        'start': tags[tag_commits[i]],\n",
    "        'prs': [],\n",
    "        'end': tags[tag_commits[i+1]],\n",
    "    })\n",
    "\n",
    "for c in sections:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_commits = [c for c in commits if c in prs]\n",
    "if commits.index(pr_commits[0]) > commits.index(tag_commits[-1]):\n",
    "    print(\"WARNING - alla releases kommer innan första PR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "19\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "sec = -1\n",
    "for commit in commits:\n",
    "    if 0 <= sec < len(sections) and commit in prs:\n",
    "        sections[sec]['prs'].append(prs[commit])\n",
    "    if commit in tags:\n",
    "        # Inkludera sista PR om den skulle vara en tag\n",
    "        # OBS: den första ska inte inkuderas - annars bli diffen fel\n",
    "        sec += 1\n",
    "        \n",
    "for section in sections:\n",
    "    print(len(section['prs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': '2.0.0',\n",
       " 'prs': [{'title': 'update click minimum version',\n",
       "   'sha': '905e5c23e8c5f6362b38ec1b5526fe999f491229'},\n",
       "  {'title': 'Fix typo in the example of nesting bp docs',\n",
       "   'sha': 'd575de5159a6e40944275763c9ada2801214058b'},\n",
       "  {'title': 'converters have access to session',\n",
       "   'sha': '9039534eee6a87da98a1dee9e4338d1b73e861f8'}],\n",
       " 'end': '2.0.1'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporär lösning, hårdkoda några random sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(len(prs))\\nrelease_indices = [5, 40, 100, 435]\\n\\nsections = []\\nfor i in range(len(release_indices)-1):\\n    start = release_indices[i]\\n    end = release_indices[i+1]\\n    sections.append({\\n        'start': pr_commits[start],\\n        'prs': pr_commits[start+1:end],\\n        'end': pr_commits[end],\\n    })\\n\\nsections[0]\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(len(prs))\n",
    "release_indices = [5, 40, 100, 435]\n",
    "\n",
    "sections = []\n",
    "for i in range(len(release_indices)-1):\n",
    "    start = release_indices[i]\n",
    "    end = release_indices[i+1]\n",
    "    sections.append({\n",
    "        'start': pr_commits[start],\n",
    "        'prs': pr_commits[start+1:end],\n",
    "        'end': pr_commits[end],\n",
    "    })\n",
    "\n",
    "sections[0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Changes - modified only (ignore adds, dels)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 changes ['CHANGES.rst', 'CONTRIBUTING.rst', 'README.rst'] ...\n",
      "25 changes ['CHANGES.rst', 'CONTRIBUTING.rst', 'README.rst'] ...\n",
      "16 changes ['CHANGES.rst', 'docs/api.rst', 'docs/cli.rst'] ...\n"
     ]
    }
   ],
   "source": [
    "def doc_file(path):\n",
    "    l = path\n",
    "    return (l.endswith('.md') or l.endswith('.rst')) # and l.startswith('doc/')\n",
    "\n",
    "chdir(repo_dir)\n",
    "try:\n",
    "    subprocess.run(\"git checkout main\", shell=True)\n",
    "    \n",
    "    for section in sections:\n",
    "        # Extract actual changes from history\n",
    "        start = section['start']\n",
    "        end = section['end']\n",
    "        command = f\"git diff '{start}' '{end}' --name-only\"\n",
    "        lines = subprocess.getoutput(command).split('\\n')\n",
    "        changes = list(filter(doc_file, lines))\n",
    "        section['changes'] = changes\n",
    "        print(len(changes), 'changes', changes[:3], '...')\n",
    "        \n",
    "finally:\n",
    "    chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': '2.0.0',\n",
       " 'prs': [{'title': 'update click minimum version',\n",
       "   'sha': '905e5c23e8c5f6362b38ec1b5526fe999f491229'},\n",
       "  {'title': 'Fix typo in the example of nesting bp docs',\n",
       "   'sha': 'd575de5159a6e40944275763c9ada2801214058b'},\n",
       "  {'title': 'converters have access to session',\n",
       "   'sha': '9039534eee6a87da98a1dee9e4338d1b73e861f8'}],\n",
       " 'end': '2.0.1',\n",
       " 'changes': ['CHANGES.rst',\n",
       "  'CONTRIBUTING.rst',\n",
       "  'README.rst',\n",
       "  'docs/blueprints.rst',\n",
       "  'docs/deploying/index.rst',\n",
       "  'docs/patterns/viewdecorators.rst',\n",
       "  'docs/quickstart.rst',\n",
       "  'examples/tutorial/README.rst']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hämta docs filer, så som de såg ut i början av varje PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(start_dir, ext):\n",
    "    \"\"\" Search files recursively \"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(start_dir):\n",
    "        path = start_dir + \"/\" + file\n",
    "        if os.path.isdir(path):\n",
    "            files += find(path, ext)\n",
    "        elif os.path.isfile(path) and file.endswith(ext):\n",
    "            files.append(path)\n",
    "    return files\n",
    "\n",
    "def read(path):\n",
    "    with open(path) as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "def extract_docs(exts=['.md', '.rst']):\n",
    "    docs = {}\n",
    "    for ext in exts:\n",
    "        paths = find(repo_dir, ext)\n",
    "        for path in paths:\n",
    "            key = path[len(repo_dir)+1:]\n",
    "            docs[key] = read(path)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "pr_shas = []\n",
    "for section in sections:\n",
    "    pr_shas += [pr['sha'] for pr in section['prs']]\n",
    "print(len(pr_shas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 24.81it/s]\n"
     ]
    }
   ],
   "source": [
    "docs = {}\n",
    "for sha in tqdm(pr_shas):\n",
    "    # Modellen behöver veta hur docs var innan PR, därför ^1\n",
    "    # antag att varje PR består av 1 commit i master\n",
    "    # det går att lösa annars också, men det blir mer komplicerat och involverar GitHub's API\n",
    "    subprocess.run(f'git checkout {sha}^1', shell=True)\n",
    "    docs[sha] = extract_docs()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **TODO: Extrahera filer, filnamn i uppdaterat format (ladda från sido-repo)**\n",
    "- **TODO: Metadata för varje PR**\n",
    "- **TODO: prova om det går att använda base_sha istället för ^1**\n",
    "- **TODO: Hitta repo som fungerar**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(pr, all_docs):\n",
    "    return all_docs\n",
    "\n",
    "def predict_none(pr, all_docs):\n",
    "    return []\n",
    "\n",
    "def predict_tfidf(pr, all_docs):\n",
    "    \n",
    "    def search(text, tfidf):\n",
    "        query = vectorizer.transform([text])\n",
    "        cosine_sims = linear_kernel(query, tfidf).flatten()\n",
    "        return sorted(zip(cosine_sims, doc_files), reverse=True)\n",
    "    \n",
    "    doc_files = list(all_docs.keys())\n",
    "    corpus = [all_docs[doc] for doc in doc_files]\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    result = []\n",
    "    for match in search(pr['title'], tfidf):\n",
    "        result.append(match[1])\n",
    "    return result[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.3670886075949367\n",
      "precision: 0.26605504587155965\n",
      "recall: 0.5918367346938775\n"
     ]
    }
   ],
   "source": [
    "predict = predict_tfidf\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for section in sections:\n",
    "    actual_changes = set(section['changes'])\n",
    "    \n",
    "    model_changes = set()\n",
    "    for pr in section['prs']:\n",
    "        prediction = set(predict(pr, docs[pr['sha']]))\n",
    "        model_changes = model_changes.union(prediction)\n",
    "    \n",
    "    tp += len(actual_changes.intersection(model_changes))\n",
    "    fp += len(model_changes.difference(actual_changes))\n",
    "    fn += len(actual_changes.difference(model_changes))\n",
    "    \n",
    "\n",
    "try:\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "except ZeroDivisionError:\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "\n",
    "\n",
    "print(\"f1:\", f1)\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
